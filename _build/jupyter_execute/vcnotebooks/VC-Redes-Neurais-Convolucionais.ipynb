{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c4ffd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# [Visão Computacional](https://denmartins.github.io/teaching/2025-visao-computacional)\n",
    "\n",
    "## Redes Neurais Convolucionais (CNNs)\n",
    "\n",
    "### [Prof. Dr. Denis Mayr Lima Martins](https://denmartins.github.io/)\n",
    "\n",
    "### [Pontifícia Universidade Católica de Campinas](https://www.puc-campinas.edu.br/)\n",
    "\n",
    "<img src=\"https://www.puc-campinas.edu.br/wp-content/uploads/2022/06/logo-puc.png\" width=\"100px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1bf642",
   "metadata": {},
   "source": [
    "## Recap: MLP para o MNIST dataset\n",
    "---\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://editor.analyticsvidhya.com/uploads/95577cnn2.gif' alt='MLP para MNIST dataset.' style=\"width:600px;\"/>\n",
    "    <span style='display:block;'>MLP para MNIST dataset. Fonte: <a href=\"https://editor.analyticsvidhya.com/uploads/95577cnn2.gif\" target=\"_blank\"> Analytics Vidhya</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35148608",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Neurônio da Camada Escondida\n",
    "---\n",
    "\n",
    "<center>\n",
    "<table style=\"width:100%;border:none;\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle;text-align:center;border:none;\">\n",
    "    <img src='https://ml4a.github.io/images/figures/mnist_1layer.png' style=\"width:100%;\"/>\n",
    "    <span style='display:block;'>Rede de 1 camada para o MNIST dataset. Fonte: <a href=\"https://ml4a.github.io/ml4a/looking_inside_neural_nets/\" target=\"_blank\">ML4a</a>.</span>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle;text-align:center;border:none;\">\n",
    "    <img src='https://ml4a.github.io/images/figures/weights_analogy_1.png' style=\"width:100%;\"/>\n",
    "    <span style='display:block;'>Net input de um neurônio na camada escondida. Fonte: <a href=\"https://ml4a.github.io/ml4a/looking_inside_neural_nets/\" target=\"_blank\">ML4a</a>.</span>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d8d70",
   "metadata": {},
   "source": [
    "## Neurônio da Camada Escondida\n",
    "---\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='\n",
    "    https://ml4a.github.io/images/figures/rolled_weights_mnist_0.png' alt='Representação em Imagem de um Neurônio da Camada Escondida de uma MLP para o MNIST dataset.' style=\"width:800px;\"/>\n",
    "    <span style='display:block;'>Representação em Imagem de um Neurônio da Camada Escondida de uma MLP para o MNIST dataset. Fonte: <a href=\"https://ml4a.github.io/ml4a/looking_inside_neural_nets/\" target=\"_blank\"> ML4a</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa5805",
   "metadata": {},
   "source": [
    "## Neurônio da Camada Escondida\n",
    "---\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='\n",
    "    https://ml4a.github.io/images/figures/rolled_weights_mnist.png' alt='Visualização dos Neurônios da Camada de Saída de uma MLP para o MNIST dataset.' style=\"width:800px;\"/>\n",
    "    <span style='display:block;'>Visualização dos Neurônios da Camada de Saída de uma MLP para o MNIST dataset.. Fonte: <a href=\"https://ml4a.github.io/ml4a/looking_inside_neural_nets/\" target=\"_blank\"> ML4a</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2886ca",
   "metadata": {},
   "source": [
    "## Limitações da Rede MLP\n",
    "---\n",
    "\n",
    "- **Dimensionalidade Alta:** Uma imagem 224x244x3 tem 150.528 pixels/entradas. Cada neurônio na primeira camada oculta de um MLP precisaria de 150.528 pesos, levando a bilhões de parâmetros treináveis em uma rede profunda.\n",
    "- O grande número de parâmetros torna o modelo propenso a **overfitting** (superajuste).\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='\n",
    "    https://learnopencv.com/wp-content/uploads/2023/01/tensorflow-keras-mlp-parameters-1024x414.png' alt='MLPs têm alta dimensionalidade.' style=\"width:800px;\"/>\n",
    "    <span style='display:block;'>Alta dimensionalidade das MLPs para imagens. Frequentemente levando a overfitting. Fonte: <a href=\"https://learnopencv.com/understanding-convolutional-neural-networks-cnn/\" target=\"_blank\"> LearnOpenCV</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66dae45",
   "metadata": {},
   "source": [
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://media.datacamp.com/legacy/v1700044100/image3_93b1b7c0d9.png' alt='Underfitting versus Overfitting.' style=\"width:800px;\"/>\n",
    "    <span style='display:block;'>Underfitting versus Overfitting. Fonte: <a href=\"https://www.datacamp.com/pt/tutorial/introduction-to-convolutional-neural-networks-cnns\" target=\"_blank\"> DataCamp</a>.</span>\n",
    "    <br/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab184d",
   "metadata": {},
   "source": [
    "## Limitações da Rede MLP\n",
    "---\n",
    "- **Perda de Estrutura Espacial:** MLPs exigem que a imagem 2D/3D seja \"achatada\" (flattened) em um vetor 1D.\n",
    "- Isso destrói a informação de localidade: pixels próximos (semânticos) são tratados da mesma forma que pixels distantes.\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://learnopencv.com/wp-content/uploads/2023/01/tensorflow-keras-mlp-image-translation.png' alt='MLPs não são invariantes à translação' style=\"width:800px;\"/>\n",
    "    <span style='display:block;'>MLPs não são invariantes à translação. Fonte: <a href=\"https://learnopencv.com/understanding-convolutional-neural-networks-cnn/\" target=\"_blank\"> LearnOpenCV</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5f894a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objetivos de Aprendizagem\n",
    "---\n",
    "\n",
    "- Explicar por que CNNs são adequadas para dados de imagem.  \n",
    "- Descrever os blocos fundamentais (convolução, padding, stride, pooling, ativação).  \n",
    "- Esboçar uma arquitetura simples de CNN e justificar cada componente.  \n",
    "- Implementar um CNN mínimo em PyTorch que classifica dígitos MNIST.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d4322",
   "metadata": {},
   "source": [
    "## Redes Neurais Convolucionais\n",
    "---\n",
    "\n",
    "- Convolutional Neural Nets (**CNNs** ou ConvNets) são arquiteturas de redes neurais otimizadas para dados com estrutura de grade, como imagens.\n",
    "- CNN aplica uma série de transformações na imagem original (veja esquema abaixo) com três tipos de camadas (**convolution, pooling e fully connected**).\n",
    "- A sequência de camadas antes da camada fully connected é chamada de extrator de características.\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://wiki.pathmind.com/images/wiki/convnet.png' alt='Exemplo de CNN' style=\"width:800px;\"/>\n",
    "    <span style='display:block;'>Estrutura geral de uma CNN. Fonte: <a href=\"https://wiki.pathmind.com/convolutional-network\" target=\"_blank\"> pathmind</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782cf8e",
   "metadata": {},
   "source": [
    "## Demo de CNN para o MNIST\n",
    "---\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://www.popsci.com/wp-content/uploads/2019/03/18/YJNDG7MQQDINTOGCDUJGTHZ4N4.png' alt='Demonstração de CNN para MNIST' style=\"width:400px;\"/>\n",
    "    <span style='display:block;'>Estrutura geral de uma CNN. Fonte: <a href=\"https://adamharley.com/nn_vis/cnn/3d.html\" target=\"_blank\"> Adam W. Harley</a>.</span>\n",
    "    <br/>\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e2bef",
   "metadata": {},
   "source": [
    "## CNN em Pytorch: Demo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ec48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            # Primeira camada convolucional\n",
    "            # Input: 1 canal (grayscale). Output: 32 filtros. Kernel: 3x3.\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # Segunda camada convolucional\n",
    "            # Input: 32 canais. Output: 64 filtros.\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2, padding=1),\n",
    "            # Pooling Max: 2x2\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            # Camada FC será definida após o cálculo do tamanho de flatten.\n",
    "            nn.Flatten(),\n",
    "            # Definindo as camadas FC\n",
    "            # Camada Totalmente Conectada 1\n",
    "            nn.Linear(14400, 128),\n",
    "            nn.ReLU(),\n",
    "            # Camada de Saída (10 classes para MNIST)\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6ec630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/p7/p37cm2fj10xgjrjj5rzdm66c0000gn/T/ipykernel_6090/4188437962.py\", line 1, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/matplotlib/__init__.py\", line 161, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/matplotlib/rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/matplotlib/colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/matplotlib/scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/matplotlib/ticker.py\", line 143, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/matplotlib/transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/__init__.py:161\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/rcsetup.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/colors.py:57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/scale.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[1;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[1;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/ticker.py:143\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[1;32m    145\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    147\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    148\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    149\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    156\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/transforms.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb022257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de processos para o dataloader\n",
    "NUM_WORKERS = 0\n",
    "# Quantas amostras (imagens) por batch\n",
    "BATCH_SIZE = 128\n",
    "# Converte dados em tensores\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Carrega dados de treino e teste\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "    download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "    download=True, transform=transform)\n",
    "\n",
    "# Cria dataset de validação\n",
    "VALIDATION_SIZE = 0.1\n",
    "n_train_examples = int(len(train_data) * VALIDATION_SIZE)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(\n",
    "    train_data, [n_train_examples, n_valid_examples])\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, \n",
    "   batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "   batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "  batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c35828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device(on_gpu=True):\n",
    "    has_mps = torch.backends.mps.is_available()\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    return \"mps\" if (has_mps and on_gpu) \\\n",
    "            else \"cuda\" if (has_cuda and on_gpu) \\\n",
    "            else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc13f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. Parâmetros no modelo: 1853034\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "EPOCHS = 10\n",
    "device = set_device(on_gpu=True)\n",
    "model = SimpleCNN()\n",
    "model = model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Num. Parâmetros no modelo:\", num_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff37b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(output, target):\n",
    "    predicted_digits = output.argmax(1)                            # Posição com maior valor da saída\n",
    "    correct_ones = (predicted_digits == target).type(torch.float)  # 1.0 se acertou, 0.0 caso contrário\n",
    "    return correct_ones.sum().item()                               # Conta o número de acertos\n",
    "\n",
    "def train_model_mini_batch_with_validation(epochs, train_loader, valid_loader, model, loss_function, optimizer):\n",
    "    tr_loss = [0.]*epochs\n",
    "    val_loss = [0.]*epochs\n",
    "\n",
    "    with trange(epochs, desc=\"Training\", leave=False) as tepoch:\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_total_loss = 0.0\n",
    "            total_correct = 0.0\n",
    "           \n",
    "\n",
    "            for data, target in train_loader:\n",
    "                # Copia dados para o device (ex.: GPU)\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                output = model(data)\n",
    "                \n",
    "                # Calcula loss\n",
    "                loss = loss_function(output, target)\n",
    "                train_total_loss += loss.item()\n",
    "\n",
    "                # Conta acertos\n",
    "                total_correct += correct(output, target)\n",
    "                \n",
    "                # Backward pass: Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            avg_tr_loss = train_total_loss / len(train_loader)\n",
    "            tr_loss[epoch] = avg_tr_loss\n",
    "            training_accuracy = total_correct / len(train_loader.dataset) * 100\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            val_total_loss = 0.0\n",
    "            val_total_correct = 0\n",
    "            \n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data, target in valid_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "                    \n",
    "                    # Calcula loss\n",
    "                    loss = loss_function(output, target)\n",
    "                    val_total_loss += loss.item()\n",
    "\n",
    "                    # Conta acertos\n",
    "                    val_total_correct += correct(output, target)\n",
    "\n",
    "            avg_val_loss = val_total_loss / len(valid_loader)\n",
    "            val_loss[epoch] = avg_val_loss\n",
    "            validation_accuracy = val_total_correct / len(valid_loader.dataset) * 100\n",
    "            tepoch.set_postfix(train_loss=avg_tr_loss, train_acc=training_accuracy, val_loss=avg_val_loss, val_acc=validation_accuracy)\n",
    "            tepoch.update(1)\n",
    "\n",
    "    epoch_ticks = [i+1 for i in range(epochs)]\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.lineplot(x=epoch_ticks, y=tr_loss, marker=\"o\", label=\"Train. Loss\" )\n",
    "    sns.lineplot(x=epoch_ticks, y=val_loss, marker=\"^\", linestyle=\"--\", label=\"Valid. Loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(\"Comportamento da Loss\")\n",
    "    plt.legend()\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c3b776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac315596bd7f44a09c8efdb37d2dee1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model_mini_batch_with_validation(\n",
    "    EPOCHS, \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    model, \n",
    "    loss_function, \n",
    "    optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b6c2e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Convolução em CNNs\n",
    "---\n",
    "\n",
    "<center>\n",
    "<table style=\"width:100%;border:none;\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle;text-align:left;border:none;\">\n",
    "\n",
    "- O bloco fundamental de uma CNN é a **Camada Convolucional**.\n",
    "- A convolução é uma busca por padrões: o filtro desliza sobre a imagem, procurando por uma característica específica.\n",
    "- Se o padrão do filtro corresponder à região da imagem, o resultado será um valor alto (ativação).\n",
    "- **Conectividade Local:** Os neurônios da CNN se conectam apenas a uma pequena região local do volume de entrada, chamada **campo receptivo**.\n",
    "- Isso explora a correlação local, pois as características importantes (bordas, curvas) são localizadas.\n",
    "\n",
    "</td>\n",
    "<td style=\"vertical-align:middle;text-align:center;border:none;\">\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz43.png\"/>\n",
    " <span style='display:block;'>Convolução na camada escondida. Fonte: <a href=\"http://neuralnetworksanddeeplearning.com/chap6.html\" target=\"_blank\">Michael Nielsen</a>.</span>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904fe558",
   "metadata": {},
   "source": [
    "## Convolução em CNNs\n",
    "---\n",
    "\n",
    "<center>\n",
    "<table style=\"width:100%;border:none;\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle;text-align:left;border:none;width:40%;\">\n",
    "\n",
    "- Cada filtro na camada convolucional aprende a detectar um tipo de característica (**feature**).\n",
    "- Nas camadas iniciais, os filtros detectam características de baixo nível, como bordas horizontais, verticais e curvas.\n",
    "- **O filtro em si é uma matriz de pesos (parâmetros) cujos valores são aprendidos durante o treinamento via backpropagation.**\n",
    "\n",
    "</td>\n",
    "<td style=\"vertical-align:middle;text-align:center;border:none;\">\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz44.png\" width=\"600\">\n",
    " <span style='display:block;'>Convolução no primeiro neurônio da camada escondida. Fonte: <a href=\"http://neuralnetworksanddeeplearning.com/chap6.html\" target=\"_blank\">Michael Nielsen</a>.</span>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e020d49",
   "metadata": {},
   "source": [
    "## Convolução em CNNs\n",
    "---\n",
    "\n",
    "- A operação de convolução (para fins de CNN) é o **produto escalar** (multiplicação elemento a elemento seguida por soma) entre o filtro e a região de entrada correspondente.\n",
    "$$ \\text{Output} = \\sum_{i, j} (\\text{Input}_{i, j} \\times \\text{Filter}_{i, j}) + \\text{Bias} $$\n",
    "- O resultado é um único número que mede o grau de correspondência do filtro com a região de entrada.\n",
    "- Esse processo é repetido para cada localização onde o filtro desliza.\n",
    "- Os resultados são colocados em uma matriz de saída chamada **Mapa de Ativação** (Activation Map) ou **Mapa de Características** (Feature Map).\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_detailedview_demo.gif' alt='Convolução CNN' style=\"width:400px;\"/>\n",
    "    <span style='display:block;'>Convolução e Feature Map. Fonte: <a href=\"https://poloclub.github.io/cnn-explainer/\" target=\"_blank\"> CNN Explainer</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90280ef8",
   "metadata": {},
   "source": [
    "## Convolução 3D\n",
    "---\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://framerusercontent.com/images/ZS9Atu2axnCtVjlj1gKbXMLAA78.png' alt='Convolução CNN' style=\"width:600px;\"/>\n",
    "    <span style='display:block;'>Convolução e Volume. Fonte: <a href=\"https://www.v7labs.com/blog/convolutional-neural-networks-guide\" target=\"_blank\"> V7 Labs</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fab424",
   "metadata": {},
   "source": [
    "## Hyperparâmetros da Convolução\n",
    "\n",
    "- **Kernel Size ($F$):** Tamanhos comuns são $3 \\times 3$ ou $5 \\times 5$. Tamanhos menores são frequentemente melhores para expressar características mais fortes com menos parâmetros.\n",
    "- **Número de Filtros:** Aumenta com a profundidade; geralmente começa em 32 e dobra (64, 128, etc.).\n",
    "- **Stride ($S$):** É o número de pixels que o filtro se move (desloca) sobre a entrada a cada iteração.\n",
    "    - **Stride = 1:** O filtro se move um pixel por vez, resultando em sobreposição de campos receptivos e um mapa de ativação grande.\n",
    "    - **Stride > 1:** Causa um \"salto\" maior do filtro, resultando em menos etapas e um mapa de ativação espacialmente menor.\n",
    "    - Um *stride* maior reduz a dimensionalidade e o custo computacional.\n",
    "- **Padding**: É a adição de pixels extras (geralmente com valor zero, **Zero-Padding**) em torno das bordas da imagem de entrada.\n",
    "    - **Problema de Redução:** Sem padding, a convolução geralmente reduz o tamanho espacial da saída. Padding garante que os pixels de borda (que seriam pouco usados) participem do campo receptivo.\n",
    "    - **Padding \"Same\" (Igual):** Adiciona zeros o suficiente para que a dimensão espacial da saída seja a mesma da entrada (assumindo $S=1$).\n",
    "    - **Padding \"Valid\" (Válido):** Não usa padding, resultando em uma saída menor que a entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee3a36",
   "metadata": {},
   "source": [
    "## Mapa de Ativação\n",
    "---\n",
    "**Determinando o Tamanho do Mapa de Ativação**:\n",
    "- O tamanho espacial de saída $O$ de uma camada convolucional é determinado pela dimensão de entrada ($N$), tamanho do kernel ($F$), Padding ($P$) e Stride ($S$).\n",
    "- Para que o resultado seja um inteiro, a fórmula abaixo deve ser satisfeita.\n",
    "\n",
    "$$ O = \\lfloor \\frac{N - F + 2P}{S} \\rfloor + 1 $$\n",
    "\n",
    "\n",
    "**Exemplo**: Imagem de entrada $32 \\times 32$ ($N=32$), Kernel $5 \\times 5$ ($F=5$).\n",
    "- **Cenário 1 (Stride e Padding):** Stride $S=1$. Para obter *Same Padding* (preservar 32x32), $P$ deve ser: $P = (F-1)/2 = (5-1)/2 = 2$.\n",
    "    - $O = \\frac{32 - 5 + 2(2)}{1} + 1 = \\frac{31}{1} + 1 = 32$\n",
    "    - A saída é $32 \\times 32$ (tamanho preservado).\n",
    "- **Cenário 2 (Sem Padding, Stride 1):** $P=0, S=1$.\n",
    "    - $O = \\frac{32 - 5 + 0}{1} + 1 = 27 + 1 = 28 $\n",
    "    - A saída é $28 \\times 28$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951b066",
   "metadata": {},
   "source": [
    "\n",
    "## Compartilhamento de Parâmetros\n",
    "---\n",
    "\n",
    "- O **Compartilhamento de Parâmetros** é uma característica distintiva das CNNs.\n",
    "- O mesmo filtro (conjunto de pesos) é usado em todas as posições espaciais da camada de entrada. \n",
    "- Para um filtro 5x5: $\\sigma\\left(b + \\sum_{l=0}^4 \\sum_{m=0}^4  w_{l,m} a_{j+l, k+m} \\right)$\n",
    "- **Vantagem I: Redução de Parâmetros:** Em vez de cada neurônio ter seu próprio conjunto de pesos, muitos neurônios compartilham o mesmo filtro.\n",
    "- **Vantagem II: Equivariância à Translação:** Se uma característica (ex: uma linha) for útil em uma parte da imagem, ela será útil em qualquer outra parte.\n",
    "- O filtro aprende a detectar a característica independentemente da sua localização exata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed21997f",
   "metadata": {},
   "source": [
    "## Função de Ativação (ReLU)\n",
    "---\n",
    "- Após a operação de convolução (que é linear), uma função de ativação é aplicada ao mapa de ativação para introduzir não-linearidade.\n",
    "- **ReLU** é a função mais comum: $f(x) = \\max(0, x)$.\n",
    "- Ela remove valores negativos, ajustando-os para zero, o que pode ser visto como uma função de limiar (thresholding).\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src='https://www.bouvet.no/bouvet-deler/understanding-convolutional-neural-networks-part-1/_/attachment/inline/8dd1e76d-a5bc-4a55-8f8d-b5fc2085a148:046fe87f48f07020b5cf6e8198a97a233faa78a9/Screenshot%202019-07-01%20at%2013.17.12.png' alt='Efeito da ReLU' style=\"width:600px;\"/>\n",
    "    <span style='display:block;'>Efeito da ReLU. Fonte: <a href=\"https://www.bouvet.no/bouvet-deler/understanding-convolutional-neural-networks-part-1\" target=\"_blank\"> Bouvet</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c28b18",
   "metadata": {},
   "source": [
    "## Pooling (Subamostragem)\n",
    "---\n",
    "\n",
    "- O **Pooling** é uma forma de subamostragem (downsampling) não linear, geralmente inserida periodicamente entre camadas convolucionais.\n",
    "- **Objetivos Principais:**\n",
    "    - Reduzir a dimensionalidade espacial (Altura e Largura).\n",
    "    - Reduzir o número de parâmetros e a quantidade de computação.\n",
    "    - Ajudar a controlar o overfitting.\n",
    "    - Conceder um grau de **invariância local à translação**.\n",
    "- O filtro de pooling **não tem parâmetros treináveis** (não tem pesos).\n",
    "- Um $2 \\times 2$ Max Pooling com $S=2$ descarta 75% das ativações espaciais\n",
    "\n",
    "<table style=\"width:100%;border:none;\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle;text-align:center;border:none;\">\n",
    "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/max-pooling-a.png?711b14799d07f9306864695e2713ae07\" width=\"400\">\n",
    " <span style='display:block;'>Max pooling. Fonte: <a href=\"https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\" target=\"_blank\">Stanford.edu</a>.</span>\n",
    "\n",
    "</td>\n",
    "<td style=\"vertical-align:middle;text-align:center;border:none;\">\n",
    "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/average-pooling-a.png?58f9ab6d61248c3ec8d526ef65763d2f\" width=\"400\">\n",
    "<span style='display:block;'>Average pooling. Fonte: <a href=\"https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\" target=\"_blank\">Stanford.edu</a>.</span>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ea44b",
   "metadata": {},
   "source": [
    "## Pooling: Exemplo numérico\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src=\"https://github.com/rasbt/machine-learning-book/blob/main/ch14/figures/14_08.png?raw=true\" width=\"600\">\n",
    " <span style='display:block;'>Pooling. Fonte: <a href=\"https://github.com/rasbt/machine-learning-book/blob/main/ch14/figures/14_08.png\" target=\"_blank\">Sebastian Raschka</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e600eb",
   "metadata": {},
   "source": [
    "## Fully Connected (FC)\n",
    "---\n",
    "\n",
    "- Após uma série de camadas Convolucionais e de Pooling, o volume de dados contém características de alto nível.\n",
    "- A última etapa é a classificação, realizada por camadas **Totalmente Conectadas (FC)** (ou densas).\n",
    "- **Flattening (Achatamento):** O volume 3D final do extrator de características deve ser convertido em um vetor 1D antes de entrar na primeira camada FC.\n",
    "- As camadas FC mapeiam as características extraídas para as probabilidades de classe.\n",
    "- O número de neurônios na camada de saída é igual ao número de classes (e.g., 10 para MNIST).\n",
    "- Para classificação de imagens: A camada de saída do classificador FC tipicamente usa a função de ativação **Softmax** para converter os valores brutos de saída da rede em probabilidades normalizadas.\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/fully-connected-ltr.png?32caf9e07c79d652faa292812579d063\" width=\"400\">\n",
    " <span style='display:block;'>Camada FC. Fonte: <a href=\"https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks\" target=\"_blank\">Stanford.edu</a>.</span>\n",
    "    <br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96b78e",
   "metadata": {},
   "source": [
    "## Arquitetura CNN\n",
    "---\n",
    "\n",
    "- Uma CNN de classificação é dividida em duas partes principais:\n",
    "    1.  **Extrator de Características (Feature Extractor):** Composto por blocos Conv + ReLU + Pooling (ou ConvBlocks). É comum empilhar 2 ou 3 camadas Conv/ReLU consecutivas antes de uma camada Pooling.\n",
    "    2.  **Classificador (Classifier):** Composto por camadas Fully Connected (FC) + Softmax.\n",
    "- O fluxo de dados transforma o volume de entrada, tipicamente reduzindo as dimensões espaciais (H, W) e aumentando a profundidade (Canais/Filtros).\n",
    "- **Hierarquia de Características:**\n",
    "    - Camadas iniciais aprendem elementos simples (bordas, cores).\n",
    "    - Camadas médias combinam elementos simples em formas mais complexas (e.g., olhos, rodas).\n",
    "    - Camadas profundas aprendem conceitos abstratos de alto nível (e.g., faces, objetos inteiros).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style='align: left; text-align:center;'>\n",
    "    <img src=\"https://learnopencv.com/wp-content/uploads/2023/01/tensorflow-keras-convolutional-blocks-summary-1024x299.png\" width=\"600\">\n",
    " <span style='display:block;'>Exemplo de Arquitetura de uma CNN. Fonte: <a href=\"https://learnopencv.com/understanding-convolutional-neural-networks-cnn/\" target=\"_blank\">LearnOpenCV</a>.</span>\n",
    "    <br/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedff32",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "---\n",
    "\n",
    "- As CNNs são tipicamente treinadas usando **Aprendizado Supervisionado**.\n",
    "- Os pesos iniciais (elementos dos filtros) são definidos aleatoriamente.\n",
    "- O processo de aprendizagem utiliza o **Backpropagation** e o **Gradiente Descendente**.\n",
    "- **Loss Function (Função de Perda):** Mede o erro entre a previsão da rede e o rótulo verdadeiro (Ground Truth).\n",
    "- **Otimização:** O algoritmo ajusta iterativamente os pesos (filtros e FC) para minimizar a perda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ded794",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Resumo\n",
    "\n",
    "---\n",
    "\n",
    "<table style=\"width:100%;border:none;\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle;text-align:left;border:none;width:65%;\">\n",
    "\n",
    "- As CNNs são inerentemente adequadas para processar imagens devido a três propriedades principais:\n",
    "    1.  **Conectividade Local:** Foca na correlação espacial, que é forte em imagens.\n",
    "    2.  **Compartilhamento de Pesos:** Reduz drasticamente os parâmetros, mitigando o overfitting e tornando o modelo escalável.\n",
    "    3.  **Pooling:** Introduz downsampling, que reduz a complexidade e a memória, e concede invariância local a pequenas variações de posição.\n",
    "- A capacidade de aprender características (filtros) automaticamente elimina a necessidade de definir manualmente os recursos visuais.\n",
    "- **Arquitetura:** CNNs são formadas por um Extrator de Características (Conv/Pooling) seguido por um Classificador (FC/Softmax).\n",
    "- **Leitura Recomendada**:\n",
    "  - [An Introduction to Convolutional Neural Networks](https://arxiv.org/pdf/1511.08458).\n",
    "  - [CNN Explainer](https://poloclub.github.io/cnn-explainer/)\n",
    "  - [ConvNets by Stanford](https://cs231n.github.io/convolutional-networks/)\n",
    "- **Mateiral adicional**: [Convolutional Neural Networks from Scratch](https://www.youtube.com/watch?v=jDe5BAsT2-Y)\n",
    "\n",
    "</td>\n",
    "<td style=\"vertical-align:middle;text-align:center;border:none;width:35%;\">\n",
    "\n",
    "    \n",
    "<div style='align:center; text-align:center;'>\n",
    "    <img src='https://hadrienj.github.io/assets/images/deep-learning-book-goodfellow-cover.jpg' style=\"width:200px;\"/>\n",
    "    <span style='display:block;'><b>Leitura Recomendada</b>: Capítulo 6.</span>\n",
    "</div> \n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db396d",
   "metadata": {},
   "source": [
    "## Perguntas e Discussão\n",
    "---\n",
    "\n",
    "1. O Perceptron Multicamadas (MLP) é a arquitetura básica de redes neurais. Por que os MLPs são inerentemente inadequados para processar imagens de alta resolução, e como a CNN supera a principal limitação de dimensionalidade do MLP?\n",
    "2. As três principais operações em um extrator de características de CNN são **Convolução**, **ReLU** e **Pooling**. Qual é a contribuição fundamental de cada uma dessas operações para a capacidade de uma CNN aprender e generalizar, especialmente no contexto de downsampling?\n",
    "3. O treinamento de uma CNN envolve o aprendizado automático de filtros (pesos). Descreva a natureza hierárquica das características aprendidas em CNNs profundas. O que um filtro (kernel) típico nas camadas iniciais detecta em comparação com as características detectadas nas camadas mais profundas?\n",
    "4.  Qual é o objetivo do **Zero-Padding** e qual o valor de padding ($P$) deve ser escolhido para um filtro de tamanho $F$ se quisermos garantir que a saída espacial ($O$) seja exatamente a mesma que a entrada espacial ($N$), assumindo um Stride ($S$) de 1? Demonstre usando a fórmula do tamanho de saída.\n",
    "5. Vimos que os filtros não são pré-definidos manualmente, mas sim aprendidos. Na fase de treinamento, como o algoritmo de Backpropagation (Retropropagação) \"sabe\" qual filtro deve ser ajustado para detectar uma curva ou uma linha, se os pesos são inicializados aleatoriamente? Por que esse processo não é considerado \"sorte\" ou aleatório?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypernn-G_MaMKSj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}